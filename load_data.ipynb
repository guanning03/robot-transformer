{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 04:08:49.128273: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-31 04:08:49.128320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-31 04:08:49.129594: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-31 04:08:55.700132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/data/zengguanning/miniconda3/envs/rtx/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"action\": {\n",
      "        \"arms_l0\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l1\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l2\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l3\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l4\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l5\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_l6\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r0\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r1\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r2\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r3\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r4\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r5\": \"Shape: (16, 32, 1)\",\n",
      "        \"arms_r6\": \"Shape: (16, 32, 1)\",\n",
      "        \"terminate_episode\": \"Shape: (16, 32, 3)\"\n",
      "    },\n",
      "    \"is_first\": \"Shape: (16, 32)\",\n",
      "    \"is_last\": \"Shape: (16, 32)\",\n",
      "    \"is_terminal\": \"Shape: (16, 32)\",\n",
      "    \"observation\": {\n",
      "        \"image_high\": \"Shape: (16, 32, 300, 300, 3)\",\n",
      "        \"image_left\": \"Shape: (16, 32, 300, 300, 3)\",\n",
      "        \"image_right\": \"Shape: (16, 32, 300, 300, 3)\",\n",
      "        \"natural_language_embedding\": \"Shape: (16, 32, 512)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import pdb\n",
    "import io\n",
    "from PIL import Image\n",
    "from format import pytree_display\n",
    "\n",
    "def load_data_from_hdf5(file_list, batch_size, file_batch_size, embedding_dict):\n",
    "    \n",
    "  def pad_and_resize(image, target_size):\n",
    "    original_size = image.size\n",
    "    ratio = float(target_size) / max(original_size)\n",
    "    new_size = tuple([int(x * ratio) for x in original_size])\n",
    "    \n",
    "    resized_image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    new_image = Image.new(\"RGB\", (target_size, target_size))\n",
    "    new_image.paste(resized_image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "  def bytes_image_to_np(image_bytes, image_size=300):\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = pad_and_resize(image, image_size)\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array[:,:,[2,1,0]] / 255.0\n",
    "    return image_array\n",
    "  \n",
    "  file_list = random.sample(file_list, file_batch_size)\n",
    "  num_per_file = batch_size // file_batch_size\n",
    "  natural_language_embedding = []\n",
    "  image = []\n",
    "  arms_action = []\n",
    "  \n",
    "  length = np.random.randint(1, 16, batch_size)\n",
    "  is_first = np.zeros((batch_size, 15), dtype=bool)\n",
    "  for i in range(batch_size):\n",
    "    if length[i] != 15:\n",
    "      is_first[i, 15 - length[i]] = True\n",
    "      \n",
    "  terminate_episode = np.zeros((batch_size, 15, 3), dtype = np.int32)\n",
    "  terminate_episode[:,:,1] = 1\n",
    "  \n",
    "  files = random.sample(file_list, file_batch_size)\n",
    "  for i, file in enumerate(files):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "      natural_language_embedding.extend([embedding_dict[f['instruction'][()].decode('utf-8')] for _ in range(num_per_file)])\n",
    "      for j in range(num_per_file):\n",
    "        l = length[i * num_per_file + j]\n",
    "        traj_l = f['action'].shape[0]\n",
    "        start = np.random.randint(0, traj_l - l + 1)\n",
    "        image.append(np.pad(np.array(list(map(bytes_image_to_np, f['observations']['images']['cam_high'][start:start+l]))),\n",
    "                            ((15 - l, 0), (0, 0), (0, 0), (0, 0)), 'constant'))\n",
    "        arms_action.append(np.pad(np.array(f['action'][start:start+l]), ((15 - l, 0), (0, 0)), 'constant'))\n",
    "  \n",
    "  batch = {\n",
    "    'is_first': np.array(is_first),\n",
    "    'observation': {\n",
    "        'image': np.array(image),\n",
    "        'natural_language': np.array(natural_language_embedding)\n",
    "        },\n",
    "    'action': {\n",
    "        'arms': np.array(arms_action),\n",
    "        'terminate_episode': terminate_episode\n",
    "    },\n",
    "    'is_last': np.zeros((batch_size, 15), dtype=bool),\n",
    "    'is_terminal': np.zeros((batch_size, 15), dtype=bool)\n",
    "    }\n",
    "  \n",
    "  return batch\n",
    "\n",
    "def load_data_from_hdf5_2(file_list, batch_size, file_batch_size, embedding_dict, max_length = 32):\n",
    "    \n",
    "    def pad_and_resize(image, target_size):\n",
    "        original_size = image.size\n",
    "        ratio = float(target_size) / max(original_size)\n",
    "        new_size = tuple([int(x * ratio) for x in original_size])\n",
    "        \n",
    "        resized_image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        new_image = Image.new(\"RGB\", (target_size, target_size))\n",
    "        new_image.paste(resized_image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "\n",
    "        return new_image\n",
    "\n",
    "    def bytes_image_to_np(image_bytes, image_size=300):\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        image = pad_and_resize(image, image_size)\n",
    "        image_array = np.array(image)\n",
    "        image_array = image_array[:,:,[2,1,0]] / 255.0\n",
    "        return image_array\n",
    "    \n",
    "    def first_frame_pad(input):\n",
    "        padding_input = np.repeat(input[:1, ...], max_length - 1, axis=0)\n",
    "        padded_input = np.concatenate([padding_input, input], axis=0)\n",
    "        return padded_input\n",
    "    \n",
    "    while True:\n",
    "        file_list_sampled = random.sample(file_list, file_batch_size)\n",
    "        num_per_file = batch_size // file_batch_size\n",
    "        natural_language_embedding = []\n",
    "        image_high = []\n",
    "        image_left = []\n",
    "        image_right = []\n",
    "        arms_action = []\n",
    "        \n",
    "        is_first = np.zeros((batch_size, max_length), dtype=bool)\n",
    "                \n",
    "        terminate_episode = np.zeros((batch_size, max_length, 3), dtype=np.int32)\n",
    "        terminate_episode[:,:,1] = 1\n",
    "        \n",
    "        for i, file in enumerate(file_list_sampled):\n",
    "            with h5py.File(file, 'r') as f:\n",
    "                text_embedding = np.array(embedding_dict[f['instruction'][()].decode('utf-8')])\n",
    "                length = f['action'].shape[0]\n",
    "                assert length >= max_length, 'Trajectory length is shorter than max_length'\n",
    "                action = np.array(f['action'])\n",
    "                action = first_frame_pad(action)\n",
    "                high = np.array(list(map(bytes_image_to_np, f['observations']['images']['cam_high'])))\n",
    "                left = np.array(list(map(bytes_image_to_np, f['observations']['images']['cam_left_wrist'])))\n",
    "                right = np.array(list(map(bytes_image_to_np, f['observations']['images']['cam_right_wrist'])))\n",
    "                high = first_frame_pad(high)\n",
    "                left = first_frame_pad(left)\n",
    "                right = first_frame_pad(right)\n",
    "                start = [np.random.randint(0, length - max_length + 1) for _ in range(num_per_file)]\n",
    "                for j in range(num_per_file):\n",
    "                    natural_language_embedding.append([text_embedding for _ in range(max_length)])\n",
    "                    traj_l = f['action'].shape[0]\n",
    "                    image_high.append(high[start[j]:start[j]+max_length])\n",
    "                    image_left.append(left[start[j]:start[j]+max_length])\n",
    "                    image_right.append(right[start[j]:start[j]+max_length])\n",
    "                    arms_action.append(action[start[j]:start[j]+max_length])\n",
    "        \n",
    "        batch = {\n",
    "            'is_first': np.array(is_first),\n",
    "            'observation': {\n",
    "                'image_high': np.array(image_high),\n",
    "                'image_left': np.array(image_left),\n",
    "                'image_right': np.array(image_right),\n",
    "                'natural_language_embedding': np.array(natural_language_embedding)\n",
    "                },\n",
    "            'action': {\n",
    "                'arms_l0': np.array(arms_action)[:,:,[0]],\n",
    "                'arms_l1': np.array(arms_action)[:,:,[1]],\n",
    "                'arms_l2': np.array(arms_action)[:,:,[2]],\n",
    "                'arms_l3': np.array(arms_action)[:,:,[3]],\n",
    "                'arms_l4': np.array(arms_action)[:,:,[4]],\n",
    "                'arms_l5': np.array(arms_action)[:,:,[5]],\n",
    "                'arms_l6': np.array(arms_action)[:,:,[6]],\n",
    "                'arms_r0': np.array(arms_action)[:,:,[7]],\n",
    "                'arms_r1': np.array(arms_action)[:,:,[8]],\n",
    "                'arms_r2': np.array(arms_action)[:,:,[9]],\n",
    "                'arms_r3': np.array(arms_action)[:,:,[10]],\n",
    "                'arms_r4': np.array(arms_action)[:,:,[11]],\n",
    "                'arms_r5': np.array(arms_action)[:,:,[12]],\n",
    "                'arms_r6': np.array(arms_action)[:,:,[13]],\n",
    "                'terminate_episode': terminate_episode\n",
    "            },\n",
    "            'is_last': np.zeros((batch_size, max_length), dtype=bool),\n",
    "            'is_terminal': np.zeros((batch_size, max_length), dtype=bool)\n",
    "            }\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "file_list = [f'data/put_orange_paperbox/episode_{i}.hdf5' for i in range(20)]\n",
    "file_batch_size = 8\n",
    "batch_size = 16\n",
    "embedding_dict = json.load(open('text_embeddings.json', 'r'))\n",
    "\n",
    "batch = load_data_from_hdf5_2(file_list, batch_size, file_batch_size, embedding_dict)\n",
    "pytree_display(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
