{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 00:54:52.685313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-22 00:54:52.685385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-22 00:54:52.686335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-22 00:54:53.536405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"action\": {\n",
      "        \"arms\": \"Shape: (16, 15, 14)\",\n",
      "        \"terminate_episode\": \"Shape: (16, 15, 3)\"\n",
      "    },\n",
      "    \"is_first\": \"Shape: (16, 15)\",\n",
      "    \"is_last\": \"Shape: (16, 15)\",\n",
      "    \"is_terminal\": \"Shape: (16, 15)\",\n",
      "    \"observation\": {\n",
      "        \"image\": \"Shape: (16, 15, 300, 300, 3)\",\n",
      "        \"natural_language\": \"Shape: (16, 512)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import pdb\n",
    "import io\n",
    "from PIL import Image\n",
    "from format import pytree_display\n",
    "\n",
    "def load_data_from_hdf5(file_list, batch_size, file_batch_size, embedding_dict):\n",
    "    \n",
    "  def pad_and_resize(image, target_size):\n",
    "    original_size = image.size\n",
    "    ratio = float(target_size) / max(original_size)\n",
    "    new_size = tuple([int(x * ratio) for x in original_size])\n",
    "    \n",
    "    resized_image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    new_image = Image.new(\"RGB\", (target_size, target_size))\n",
    "    new_image.paste(resized_image, ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "  def bytes_image_to_np(image_bytes, image_size=300):\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = pad_and_resize(image, image_size)\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array[:,:,[2,1,0]] / 255.0\n",
    "    return image_array\n",
    "  \n",
    "  file_list = random.sample(file_list, file_batch_size)\n",
    "  num_per_file = batch_size // file_batch_size\n",
    "  natural_language_embedding = []\n",
    "  image = []\n",
    "  arms_action = []\n",
    "  \n",
    "  length = np.random.randint(1, 16, batch_size)\n",
    "  is_first = np.zeros((batch_size, 15), dtype=bool)\n",
    "  for i in range(batch_size):\n",
    "    if length[i] != 15:\n",
    "      is_first[i, 15 - length[i]] = True\n",
    "      \n",
    "  terminate_episode = np.zeros((batch_size, 15, 3), dtype = np.int32)\n",
    "  terminate_episode[:,:,1] = 1\n",
    "  \n",
    "  files = random.sample(file_list, file_batch_size)\n",
    "  for i, file in enumerate(files):\n",
    "    with h5py.File(file, 'r') as f:\n",
    "      natural_language_embedding.extend([embedding_dict[f['instruction'][()].decode('utf-8')] for _ in range(num_per_file)])\n",
    "      for j in range(num_per_file):\n",
    "        l = length[i * num_per_file + j]\n",
    "        traj_l = f['action'].shape[0]\n",
    "        start = np.random.randint(0, traj_l - l + 1)\n",
    "        image.append(np.pad(np.array(list(map(bytes_image_to_np, f['observations']['images']['cam_high'][start:start+l]))),\n",
    "                            ((15 - l, 0), (0, 0), (0, 0), (0, 0)), 'constant'))\n",
    "        arms_action.append(np.pad(np.array(f['action'][start:start+l]), ((15 - l, 0), (0, 0)), 'constant'))\n",
    "  \n",
    "  batch = {\n",
    "    'is_first': np.array(is_first),\n",
    "    'observation': {\n",
    "        'image': np.array(image),\n",
    "        'natural_language': np.array(natural_language_embedding)\n",
    "        },\n",
    "    'action': {\n",
    "        'arms': np.array(arms_action),\n",
    "        'terminate_episode': terminate_episode\n",
    "    },\n",
    "    'is_last': np.zeros((batch_size, 15), dtype=bool),\n",
    "    'is_terminal': np.zeros((batch_size, 15), dtype=bool)\n",
    "    }\n",
    "  \n",
    "  return batch\n",
    "        \n",
    "        \n",
    "file_list = [f'/mnt/data_x2/wulingxuan/robot-transformer/data/arrange_fruits_by_size/episode_{i}.hdf5' for i in range(20)]\n",
    "file_batch_size = 8\n",
    "batch_size = 16\n",
    "embedding_dict = json.load(open('text_embeddings.json', 'r'))\n",
    "\n",
    "batch = load_data_from_hdf5(file_list, batch_size, file_batch_size, embedding_dict)\n",
    "pytree_display(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
